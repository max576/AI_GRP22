{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step 0: Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports here\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms, models\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision.datasets import ImageFolder\n",
    "from PIL import Image\n",
    "import json\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step 1: Load and split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to filter out folders with 5 or fewer images and count remaining classes\n",
    "def filter_folders(data_dir):\n",
    "    filtered_folders = []\n",
    "    for folder in os.listdir(data_dir):\n",
    "        folder_path = os.path.join(data_dir, folder)\n",
    "        if os.path.isdir(folder_path):\n",
    "            num_images = len(os.listdir(folder_path))\n",
    "            if num_images > 5:\n",
    "                filtered_folders.append(folder)\n",
    "    return filtered_folders, len(filtered_folders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to your data folder\n",
    "data_dir = 'data34'\n",
    "\n",
    "# Filter out folders with 5 or fewer images and count remaining classes\n",
    "filtered_folders, num_classes = filter_folders(data_dir)\n",
    "print(num_classes)\n",
    "\n",
    "# Load the dataset using ImageFolder only for filtered folders\n",
    "full_dataset = ImageFolder(root=data_dir)#r, transform=None)\n",
    "\n",
    "# Filter out samples that don't belong to filtered folders\n",
    "filtered_dataset = [(image, label) for image, label in full_dataset.samples if os.path.basename(os.path.dirname(image)) in filtered_folders]\n",
    "\n",
    "\n",
    "# Define the percentage of data to be used for testing and validation\n",
    "test_split = 0.05\n",
    "valid_split = 0.1\n",
    "\n",
    "# Calculate the number of samples for training, testing and validation\n",
    "num_samples = len(full_dataset )\n",
    "num_test_samples = int(test_split * num_samples)\n",
    "num_valid_samples = int(valid_split * num_samples)\n",
    "num_train_samples = num_samples - num_test_samples - num_valid_samples\n",
    "\n",
    "# Split the dataset into training, validation and testing sets\n",
    "train_data, valid_data, test_data = random_split(full_dataset , [num_train_samples, num_valid_samples, num_test_samples])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step 2: Transform Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training transform includes random rotation and flip to build a more robust model\n",
    "train_transforms = transforms.Compose([transforms.Resize((244,244)),\n",
    "                                       transforms.RandomRotation(30),\n",
    "                                       transforms.RandomHorizontalFlip(),\n",
    "                                       transforms.ToTensor(),\n",
    "                                       transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "\n",
    "# The validation set will use the same transform as the test set\n",
    "test_transforms = transforms.Compose([transforms.Resize((244,244)),\n",
    "                                      transforms.CenterCrop(224),\n",
    "                                      transforms.ToTensor(),\n",
    "                                      transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "validation_transforms = transforms.Compose([transforms.Resize((244,244)),\n",
    "                                            transforms.CenterCrop(224),\n",
    "                                            transforms.ToTensor(),\n",
    "                                            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the transforms to the subsets\n",
    "train_data.dataset.transform = train_transforms\n",
    "valid_data.dataset.transform = validation_transforms\n",
    "test_data.dataset.transform = test_transforms\n",
    "\n",
    "# Create dataloaders for training, validation and testing sets\n",
    "trainloader = DataLoader(train_data, batch_size=196, shuffle=True)\n",
    "print(len(trainloader))\n",
    "validloader = DataLoader(valid_data, batch_size=64, shuffle=True)\n",
    "print(len(validloader))\n",
    "testloader = DataLoader(test_data, batch_size=32, shuffle=True)\n",
    "print(len(testloader))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step 3: Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = models.densenet121(pretrained=True)\n",
    "model = models.resnet34(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "#optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "#optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.001)\n",
    "#lrscheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', patience=3, threshold = 0.9)\n",
    "lrscheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', patience=2, factor=0.5, threshold=0.9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step 4: Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement a function for the validation pass\n",
    "def validation(model, validloader, criterion):\n",
    "    valid_loss = 0\n",
    "    accuracy = 0\n",
    "    \n",
    "    # change model to work with cuda\n",
    "    model.to('cuda')\n",
    "\n",
    "    # Iterate over data from validloader\n",
    "    for ii, (images, labels) in enumerate(validloader):\n",
    "    \n",
    "        # Change images and labels to work with cuda\n",
    "        images, labels = images.to('cuda'), labels.to('cuda')\n",
    "\n",
    "        # Forward pass image though model for prediction\n",
    "        output = model.forward(images)\n",
    "        # Calculate loss\n",
    "        valid_loss += criterion(output, labels).item()\n",
    "        # Calculate probability\n",
    "        ps = torch.exp(output)\n",
    "        \n",
    "        # Calculate accuracy\n",
    "        equality = (labels.data == ps.max(dim=1)[1])\n",
    "        accuracy += equality.type(torch.FloatTensor).mean()\n",
    "    \n",
    "    return valid_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 6\n",
    "steps = 0\n",
    "print_every = 20\n",
    "\n",
    "# change to gpu mode\n",
    "model.to('cuda')\n",
    "model.train()\n",
    "for e in range(epochs):\n",
    "\n",
    "    running_loss = 0\n",
    "    \n",
    "    # Iterating over data to carry out training step\n",
    "    for ii, (inputs, labels) in enumerate(trainloader):\n",
    "        steps += 1\n",
    "        \n",
    "        inputs, labels = inputs.to('cuda'), labels.to('cuda')\n",
    "        \n",
    "        # zeroing parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward and backward passes\n",
    "        outputs = model.forward(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        # Save the model after every epoch\n",
    "        torch.save(model.state_dict(), f'epoch_save/model_epoch_{e+1}.pth')                \n",
    "\n",
    "        # Carrying out validation step\n",
    "        if steps % print_every == 0:\n",
    "            # setting model to evaluation mode during validation\n",
    "            model.eval()\n",
    "            \n",
    "            # Gradients are turned off as no longer in training\n",
    "            with torch.no_grad():\n",
    "                valid_loss, accuracy = validation(model, validloader, criterion)\n",
    "            \n",
    "            print(f\"No. epochs: {e+1}, \\\n",
    "            Training Loss: {round(running_loss/print_every,3)} \\\n",
    "            Valid Loss: {round(valid_loss/len(validloader),3)} \\\n",
    "            Valid Accuracy: {round(float(accuracy/len(validloader)),3)}\")\n",
    "            \n",
    "            \n",
    "            # Turning training back on\n",
    "            model.train()\n",
    "            lrscheduler.step(accuracy * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "model.to('cuda')\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        images, labels = images.to('cuda'), labels.to('cuda')\n",
    "        # Get probabilities\n",
    "        outputs = model(images)\n",
    "        # Turn probabilities into predictions\n",
    "        _, predicted_outcome = torch.max(outputs.data, 1)\n",
    "        # Total number of images\n",
    "        total += labels.size(0)\n",
    "        # Count number of cases in which predictions are correct\n",
    "        correct += (predicted_outcome == labels).sum().item()\n",
    "\n",
    "print(f\"Test accuracy of model: {round(100 * correct / total,3)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step 5: Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Saving: feature weights, new model.fc, index-to-class mapping, optimiser state, and No. of epochs\n",
    "# checkpoint = {'state_dict': model.state_dict(),\n",
    "#               'model': model.fc,\n",
    "#               'class_to_idx': train_data.class_to_idx,\n",
    "#               'opt_state': optimizer.state_dict,\n",
    "#               'num_epochs': epochs}\n",
    "\n",
    "# torch.save(checkpoint, 'models/my_checkpoint2.pth')\n",
    "\n",
    "checkpoint = {'state_dict': model.state_dict(),\n",
    "              'model': model.fc,\n",
    "              'class_to_idx': full_dataset.class_to_idx,  # Access class_to_idx from the original dataset\n",
    "              'opt_state': optimizer.state_dict(),\n",
    "              'num_epochs': epochs}\n",
    "\n",
    "torch.save(checkpoint, 'models/car_classifer.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step 6: Load the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a function that loads a checkpoint and rebuilds the model\n",
    "\n",
    "def load_checkpoint(filepath):\n",
    "\n",
    "    #checkpoint = torch.load(filepath)\n",
    "    checkpoint = torch.load(filepath, map_location=torch.device('cuda'))\n",
    "\n",
    "    \n",
    "    #model.load_state_dict(checkpoint['state_dict'])\n",
    "    model.load_state_dict(checkpoint['state_dict'], strict=False)\n",
    "    model.class_to_idx = checkpoint['class_to_idx']\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Loading model\n",
    "model = load_checkpoint('models/car_classifer.pth')\n",
    "# Checking model i.e. should have 196 output units in the classifier\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.nn.DataParallel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step 7: Predict the Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(image):\n",
    "    \n",
    "    # Process a PIL image for use in a PyTorch model\n",
    "\n",
    "    # Converting image to PIL image using image file path\n",
    "    pil_im = Image.open(f'{image}' + '.jpg')\n",
    "\n",
    "    # Building image transform\n",
    "    transform = transforms.Compose([transforms.Resize((244,244)),\n",
    "                                    #transforms.CenterCrop(224),\n",
    "                                    transforms.ToTensor(),\n",
    "                                    transforms.Normalize([0.485, 0.456, 0.406], \n",
    "                                                         [0.229, 0.224, 0.225])]) \n",
    "    \n",
    "    # Transforming image for use with network\n",
    "    pil_tfd = transform(pil_im)\n",
    "    \n",
    "    # Converting to Numpy array \n",
    "    array_im_tfd = np.array(pil_tfd)\n",
    "    \n",
    "    return array_im_tfd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(image, ax=None, title=None):\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots()\n",
    "    \n",
    "    # PyTorch tensors assume the color channel is the first dimension\n",
    "    # but matplotlib assumes is the third dimension\n",
    "    image = image.transpose((1, 2, 0))\n",
    "    \n",
    "    # Undo preprocessing\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    image = std * image + mean\n",
    "    \n",
    "    # Image needs to be clipped between 0 and 1 or it looks like noise when displayed\n",
    "    image = np.clip(image, 0, 1)\n",
    "    \n",
    "    ax.imshow(image)\n",
    "    \n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow(process_image(data_dir + '/1/audi_1'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(image_path, model, topk=5):\n",
    "    # Implement the code to predict the class from an image file   \n",
    "    \n",
    "    # Loading model - using .cuda() for working with cudas\n",
    "    loaded_model = load_checkpoint(model)#.to('cpu')\n",
    "    \n",
    "    # Pre-processing image\n",
    "    img = process_image(image_path)\n",
    "    # Converting to torch tensor from Numpy array\n",
    "    img_tensor = torch.from_numpy(img).type(torch.FloatTensor)\n",
    "    # Adding dimension to image to comply with (B x C x W x H) input of model\n",
    "    img_add_dim = img_tensor.unsqueeze_(0)\n",
    "\n",
    "    # Setting model to evaluation mode and turning off gradients\n",
    "    loaded_model.eval()\n",
    "    with torch.no_grad():\n",
    "        # Running image through network\n",
    "        output = loaded_model.forward(img_add_dim)\n",
    "        \n",
    "    #conf, predicted = torch.max(output.data, 1)   \n",
    "    probs_top = output.topk(topk)[0]\n",
    "    predicted_top = output.topk(topk)[1]\n",
    "    \n",
    "    # Converting probabilities and outputs to lists\n",
    "    #conf = np.array(probs_top)[0]\n",
    "    #predicted = np.array(predicted_top)[0]\n",
    "\n",
    "    # Converting probabilities and outputs to lists on cpu\n",
    "    conf = np.array(probs_top.cpu())[0]\n",
    "    predicted = np.array(predicted_top.cpu())[0]\n",
    "\n",
    "        \n",
    "    #return probs_top_list, index_top_list\n",
    "    return conf, predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV file into a pandas DataFrame\n",
    "df = pd.read_csv('Ident/class_names.csv')\n",
    "\n",
    "# Convert the DataFrame into a dictionary\n",
    "folder_to_class = df.set_index('folder_name')['class_name'].to_dict()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tie the class indices to their names\n",
    "\n",
    "def find_classes(dir):\n",
    "    classes = os.listdir(dir)\n",
    "    classes.sort()\n",
    "    class_to_idx = {classes[i]: i for i in range(len(classes))}\n",
    "    #return list(folder_to_class.values()), class_to_idx\n",
    "    return classes, class_to_idx\n",
    "classes, c_to_idx = find_classes(data_dir)#+\"train\")\n",
    "\n",
    "print(classes, c_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step 8: Show the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'models/car_classifer.pth'\n",
    "image_path = data_dir + '/1/audi_1'\n",
    "\n",
    "\n",
    "conf1, predicted1 = predict(image_path, model_path, topk=5)\n",
    "\n",
    "print(conf1)\n",
    "print(classes[predicted1[0]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing predict function\n",
    "\n",
    "# Inputs are paths to saved model and test image\n",
    "model_path = 'models/car_classifer.pth'\n",
    "carname = '/1/audi_1'\n",
    "image_path = data_dir + carname\n",
    "\n",
    "\n",
    "conf2, predicted1 = predict(image_path, model_path, topk=5)\n",
    "# Converting classes to names\n",
    "names = []\n",
    "for i in range(5):\n",
    "  \n",
    "    names += [classes[predicted1[i]]]\n",
    "\n",
    "# Creating PIL image\n",
    "image = Image.open(image_path+'.jpg')\n",
    "\n",
    "# Plotting test image and predicted probabilites\n",
    "f, ax = plt.subplots(2,figsize = (6,10))\n",
    "\n",
    "ax[0].imshow(image)\n",
    "ax[0].set_title(carname)\n",
    "\n",
    "y_names = np.arange(len(names))\n",
    "ax[1].barh(y_names, conf2/conf2.sum(), color='darkblue')\n",
    "ax[1].set_yticks(y_names)\n",
    "ax[1].set_yticklabels(names)\n",
    "ax[1].invert_yaxis() \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_solution(cardir, model):\n",
    "  # Testing predict function\n",
    "\n",
    "  # Inputs are paths to saved model and test image\n",
    "  model_path = 'models/car_classifer.pth'\n",
    "  image_path = data_dir + cardir\n",
    "  carname = cardir.split('/')[1]\n",
    "\n",
    "  conf2, predicted1 = predict(image_path, model_path, topk=5)\n",
    "  # Converting classes to names\n",
    "  names = []\n",
    "  for i in range(5):\n",
    "  \n",
    "      names += [classes[predicted1[i]]]\n",
    "\n",
    "\n",
    "  # Creating PIL image\n",
    "  image = Image.open(image_path+'.jpg')\n",
    "\n",
    "  # Plotting test image and predicted probabilites\n",
    "  f, ax = plt.subplots(2,figsize = (6,10))\n",
    "\n",
    "  ax[0].imshow(image)\n",
    "  ax[0].set_title(carname)\n",
    "\n",
    "  y_names = np.arange(len(names))\n",
    "  ax[1].barh(y_names, conf2/conf2.sum(), color='darkblue')\n",
    "  ax[1].set_yticks(y_names)\n",
    "  ax[1].set_yticklabels(names)\n",
    "  ax[1].invert_yaxis() \n",
    "\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Section that maps class_names.csv to classes for plotting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cardir='/27/bmw_1'\n",
    "plot_solution(cardir, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cardir='/270/00406'\n",
    "plot_solution(cardir, model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
